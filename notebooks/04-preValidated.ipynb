{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despite the title, \n",
    "# Run this after doing the validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "import re\n",
    "from aicsimageio import AICSImage\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the base path. \n",
    "#### Output files will have names dictated by date at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/vast/imaging/Sabrina/New_new/1064/\"\n",
    "\n",
    "today = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "dataset_label = base_path.split('/')[-2]\n",
    "\n",
    "original_met_path = os.path.join(base_path,'output_mets')\n",
    "met_path = os.path.join(original_met_path,'CORRECTED_METS')\n",
    "\n",
    "preValidated_filename = \"%s_preValidated_%s_results.csv\" % (today,dataset_label)\n",
    "validated_filename = \"%s_validated_%s_results.csv\" % (today,dataset_label)\n",
    "\n",
    "print(preValidated_filename)\n",
    "print(validated_filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all the required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_path_files = os.listdir(met_path)\n",
    "original_met_path_files = os.listdir(original_met_path)\n",
    "mets = [m for m in met_path_files if m.endswith('tif')]\n",
    "results = [r for r in original_met_path_files if r.endswith('csv')]\n",
    "notes_files = [n for n in met_path_files if n.startswith('notes')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "for notes_file in notes_files:\n",
    "    with open(os.path.join(met_path,notes_file),'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            l = line.split(',')\n",
    "            x = []\n",
    "            for idx,res in enumerate(l):\n",
    "                if idx==0:\n",
    "                    x.append(int(res))\n",
    "                else:\n",
    "                    try:\n",
    "                        x.append(float(res))\n",
    "                    except:\n",
    "                        x.append(res)\n",
    "            notes.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_results = []\n",
    "for results_file in results:\n",
    "    with open(os.path.join(original_met_path,results_file),'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            l = line.split(',')\n",
    "            x = []\n",
    "            for idx,res in enumerate(l):\n",
    "                if idx==0:\n",
    "                    x.append(int(res))\n",
    "                else:\n",
    "                    try:\n",
    "                        x.append(float(res))\n",
    "                    except:\n",
    "                        x.append(res)\n",
    "            original_results.append(x)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_validated_results = []\n",
    "\n",
    "for r in original_results:\n",
    "   # print(r)\n",
    "    r_new = r\n",
    "    try:\n",
    "        associated_note = [n for n in notes if n[0]==r[0]][0]\n",
    "        associated_note = associated_note[-1]\n",
    "    except IndexError:\n",
    "        associated_note = 'No note found'\n",
    "    #print(associated_note[-1])\n",
    "    r_new.append(associated_note)\n",
    "    res_string = ','.join(str(elem) for elem in r_new)\n",
    "    pre_validated_results.append(res_string)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res_file = os.path.join(base_path,preValidated_filename)\n",
    "with open(new_res_file,'w') as f:\n",
    "    headings = 'MET_ID,Volume,001,010,011,100,101,110,111,min_dist,max_dist,mean_dist,Nearest Vessel Thickness,notes'\n",
    "    print(headings,file=f)\n",
    "    for r in pre_validated_results:       \n",
    "        print(r,file=f)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Results are to be found in %s\" % new_res_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate all the met volumes\n",
    "#### This may take a while and it will print a bunch of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "post_validated_results = []\n",
    "idx=0\n",
    "for r in pre_validated_results:\n",
    "    print(r)\n",
    "    r_new = r.split(',')\n",
    "    met_num = int(r_new[0])\n",
    "    metFile = os.path.join(met_path,'met_%i_mask.tif' % met_num)\n",
    "    if os.path.exists(metFile):\n",
    "        print(idx)\n",
    "        idx+=1\n",
    "        print('%i - File Found' % met_num)\n",
    "        \n",
    "        maskImg = AICSImage(metFile).dask_data\n",
    "        scores = np.zeros(7)\n",
    "        \n",
    "        for c in range(0,7):\n",
    "            try:\n",
    "                thisChannel = maskImg[0,c,:,:,:]\n",
    "                n_non_zero = np.count_nonzero(thisChannel).compute()\n",
    "                scores[c] = n_non_zero\n",
    "                scores_normalised = [x / np.sum(scores) for x in scores]\n",
    "            except:\n",
    "                scores_normalised = np.zeros(7)\n",
    "        this_met_results = [met_num,r_new[1]]\n",
    "        for s in scores_normalised:\n",
    "            this_met_results.append(s)\n",
    "        this_met_results.extend(r_new[9:14])\n",
    "        print(this_met_results)\n",
    "    else:\n",
    "        print('File Not Found')\n",
    "\n",
    "    post_validated_results.append(this_met_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out validated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_filename)\n",
    "output_path = os.path.join(base_path, validated_filename)\n",
    "\n",
    "with open(output_path,'w') as f:\n",
    "    for l in post_validated_results:\n",
    "        res_string = ','.join(str(elem) for elem in l)\n",
    "        print(res_string,file=f)\n",
    "\n",
    "print(\"File can be found in %s\" % output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bac2)",
   "language": "python",
   "name": "bac2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
